{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 155541 fixture IDs.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your full fixture list\n",
    "FIXTURE_FILE = '/Users/sebastianvinther/Desktop/Sportsmonks/fixtures_full.csv'\n",
    "\n",
    "# Load fixture data\n",
    "fixtures_df = pd.read_csv(FIXTURE_FILE, low_memory=False)\n",
    "fixture_ids = fixtures_df['id'].dropna().astype(int).tolist()\n",
    "\n",
    "print(f\"Loaded {len(fixture_ids)} fixture IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# === CONFIG ===\n",
    "API_TOKEN = \"oYeoAVFUTQpu7MfoFqbvyiYfgRRkuBWW0p2atkZnySe4X3xrHkjgGhOvI0pd\"\n",
    "FIXTURE_FILE = \"/Users/sebastianvinther/Desktop/Sportsmonks/fixtures_full.csv\"\n",
    "OUTPUT_FILE = \"/Users/sebastianvinther/Desktop/Sportsmonks/fixture_statistics_parallel.csv\"\n",
    "NUM_THREADS = 2  # ⬅️ REDUCED to avoid overload\n",
    "\n",
    "# === LOAD FIXTURE IDS ===\n",
    "fixture_ids = pd.read_csv(FIXTURE_FILE)['id'].dropna().astype(int).tolist()\n",
    "\n",
    "# === SHARED SESSION ===\n",
    "session = requests.Session()\n",
    "adapter = requests.adapters.HTTPAdapter(pool_connections=100, pool_maxsize=100)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "# === FUNCTION TO FETCH STATS ===\n",
    "def fetch_fixture_stats(fixture_id):\n",
    "    url = f\"https://api.sportmonks.com/v3/football/fixtures/{fixture_id}\"\n",
    "    params = {\"api_token\": API_TOKEN, \"include\": \"statistics\"}\n",
    "    try:\n",
    "        response = session.get(url, params=params, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return []\n",
    "        stats = response.json().get(\"data\", {}).get(\"statistics\", [])\n",
    "        flat_stats = []\n",
    "        for stat in stats:\n",
    "            flat_stat = {\"fixture_id\": fixture_id}\n",
    "            for k, v in stat.items():\n",
    "                if isinstance(v, dict):\n",
    "                    for sub_k, sub_v in v.items():\n",
    "                        flat_stat[f\"{k}_{sub_k}\"] = sub_v\n",
    "                else:\n",
    "                    flat_stat[k] = v\n",
    "            flat_stats.append(flat_stat)\n",
    "        return flat_stats\n",
    "    except Exception as e:\n",
    "        print(f\"[{fixture_id}] Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# === PARALLEL EXECUTION ===\n",
    "all_stats = []\n",
    "with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "    futures = {executor.submit(fetch_fixture_stats, fid): fid for fid in fixture_ids}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching stats\"):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            all_stats.extend(result)\n",
    "\n",
    "# === SAVE TO FILE ===\n",
    "pd.DataFrame(all_stats).to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"✅ Done! Saved {len(all_stats)} rows to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/dl4x3l3x1dd8twj43d1ddkx80000gn/T/ipykernel_36048/1952628871.py:15: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fixture_ids = pd.read_csv(FIXTURE_FILE)['id'].dropna().astype(int).tolist()\n",
      "Fetching stats:   0%|          | 49/155541 [00:03<3:30:02, 12.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m\n\u001b[1;32m     51\u001b[0m futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(fetch_fixture_stats, fid): fid \u001b[38;5;28;01mfor\u001b[39;00m fid \u001b[38;5;129;01min\u001b[39;00m fixture_ids}\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching stats\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     53\u001b[0m     result \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m waiter\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mwait(wait_timeout)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m     waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m all_stats \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     48\u001b[0m completed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mNUM_THREADS) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     51\u001b[0m     futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(fetch_fixture_stats, fid): fid \u001b[38;5;28;01mfor\u001b[39;00m fid \u001b[38;5;129;01min\u001b[39;00m fixture_ids}\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching stats\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshutdown(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/thread.py:238\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 238\u001b[0m         t\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:1149\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:1169\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[1;32m   1170\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "API_TOKEN = \"oYeoAVFUTQpu7MfoFqbvyiYfgRRkuBWW0p2atkZnySe4X3xrHkjgGhOvI0pd\"\n",
    "FIXTURE_FILE = \"/Users/sebastianvinther/Desktop/Sportsmonks/fixtures_full.csv\"\n",
    "OUTPUT_FILE = \"/Users/sebastianvinther/Desktop/Sportsmonks/fixture_statistics_parallel.csv\"\n",
    "NUM_THREADS = 1\n",
    "SAVE_EVERY = 100  # Auto-save every 100 fixtures\n",
    "\n",
    "# === LOAD FIXTURE IDS ===\n",
    "fixture_ids = pd.read_csv(FIXTURE_FILE)['id'].dropna().astype(int).tolist()\n",
    "\n",
    "# === SHARED SESSION ===\n",
    "session = requests.Session()\n",
    "adapter = requests.adapters.HTTPAdapter(pool_connections=100, pool_maxsize=100)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "# === FUNCTION TO FETCH STATS ===\n",
    "def fetch_fixture_stats(fixture_id):\n",
    "    url = f\"https://api.sportmonks.com/v3/football/fixtures/{fixture_id}\"\n",
    "    params = {\"api_token\": API_TOKEN, \"include\": \"statistics\"}\n",
    "    try:\n",
    "        response = session.get(url, params=params, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return []\n",
    "        stats = response.json().get(\"data\", {}).get(\"statistics\", [])\n",
    "        flat_stats = []\n",
    "        for stat in stats:\n",
    "            flat_stat = {\"fixture_id\": fixture_id}\n",
    "            for k, v in stat.items():\n",
    "                if isinstance(v, dict):\n",
    "                    for sub_k, sub_v in v.items():\n",
    "                        flat_stat[f\"{k}_{sub_k}\"] = sub_v\n",
    "                else:\n",
    "                    flat_stat[k] = v\n",
    "            flat_stats.append(flat_stat)\n",
    "        return flat_stats\n",
    "    except Exception as e:\n",
    "        print(f\"[{fixture_id}] Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# === PARALLEL EXECUTION WITH PERIODIC SAVING ===\n",
    "all_stats = []\n",
    "completed = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "    futures = {executor.submit(fetch_fixture_stats, fid): fid for fid in fixture_ids}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching stats\"):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            all_stats.extend(result)\n",
    "        completed += 1\n",
    "\n",
    "        # Save batch\n",
    "        if completed % SAVE_EVERY == 0:\n",
    "            df = pd.DataFrame(all_stats)\n",
    "            header = not os.path.exists(OUTPUT_FILE)\n",
    "            df.to_csv(OUTPUT_FILE, mode='a', header=header, index=False)\n",
    "            print(f\"🔄 Autosaved {len(all_stats)} rows after {completed} fixtures.\")\n",
    "            all_stats = []\n",
    "\n",
    "# Final save\n",
    "if all_stats:\n",
    "    df = pd.DataFrame(all_stats)\n",
    "    header = not os.path.exists(OUTPUT_FILE)\n",
    "    df.to_csv(OUTPUT_FILE, mode='a', header=header, index=False)\n",
    "    print(f\"✅ Final save: {len(all_stats)} remaining rows.\")\n",
    "\n",
    "print(f\"🎯 Done! All fixture stats saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/dl4x3l3x1dd8twj43d1ddkx80000gn/T/ipykernel_36048/1346557750.py:15: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_fixture_ids = pd.read_csv(FIXTURE_FILE)['id'].dropna().astype(int).tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Resuming from progress: 9456 done, 146085 remaining.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:  10%|█         | 14967/146085 [21:35<3:09:07, 11.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 62\u001b[0m\n\u001b[1;32m     61\u001b[0m futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(fetch_fixture_stats, fid): fid \u001b[38;5;28;01mfor\u001b[39;00m fid \u001b[38;5;129;01min\u001b[39;00m remaining_ids}\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching stats\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     63\u001b[0m     result \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m waiter\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mwait(wait_timeout)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m     waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m all_stats \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m completed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mNUM_THREADS) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     61\u001b[0m     futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(fetch_fixture_stats, fid): fid \u001b[38;5;28;01mfor\u001b[39;00m fid \u001b[38;5;129;01min\u001b[39;00m remaining_ids}\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching stats\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshutdown(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/thread.py:238\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 238\u001b[0m         t\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:1149\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:1169\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[1;32m   1170\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "API_TOKEN = \"oYeoAVFUTQpu7MfoFqbvyiYfgRRkuBWW0p2atkZnySe4X3xrHkjgGhOvI0pd\"\n",
    "FIXTURE_FILE = \"/Users/sebastianvinther/Desktop/Sportsmonks/fixtures_full.csv\"\n",
    "OUTPUT_FILE = \"/Users/sebastianvinther/Desktop/Sportsmonks/fixture_statistics_parallel.csv\"\n",
    "NUM_THREADS = 1\n",
    "SAVE_EVERY = 100  # Save every N fetched fixtures\n",
    "\n",
    "# === LOAD FIXTURE IDS ===\n",
    "all_fixture_ids = pd.read_csv(FIXTURE_FILE)['id'].dropna().astype(int).tolist()\n",
    "\n",
    "# === LOAD PROGRESS IF EXISTS ===\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    done_ids = pd.read_csv(OUTPUT_FILE)['fixture_id'].dropna().unique().tolist()\n",
    "    remaining_ids = [fid for fid in all_fixture_ids if fid not in done_ids]\n",
    "    print(f\"🔁 Resuming from progress: {len(done_ids)} done, {len(remaining_ids)} remaining.\")\n",
    "else:\n",
    "    done_ids = []\n",
    "    remaining_ids = all_fixture_ids\n",
    "    print(f\"🆕 Starting fresh with {len(remaining_ids)} fixture IDs.\")\n",
    "\n",
    "# === SHARED SESSION ===\n",
    "session = requests.Session()\n",
    "adapter = requests.adapters.HTTPAdapter(pool_connections=100, pool_maxsize=100)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "# === FUNCTION TO FETCH STATS ===\n",
    "def fetch_fixture_stats(fixture_id):\n",
    "    url = f\"https://api.sportmonks.com/v3/football/fixtures/{fixture_id}\"\n",
    "    params = {\"api_token\": API_TOKEN, \"include\": \"statistics\"}\n",
    "    try:\n",
    "        response = session.get(url, params=params, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return []\n",
    "        stats = response.json().get(\"data\", {}).get(\"statistics\", [])\n",
    "        flat_stats = []\n",
    "        for stat in stats:\n",
    "            flat_stat = {\"fixture_id\": fixture_id}\n",
    "            for k, v in stat.items():\n",
    "                if isinstance(v, dict):\n",
    "                    for sub_k, sub_v in v.items():\n",
    "                        flat_stat[f\"{k}_{sub_k}\"] = sub_v\n",
    "                else:\n",
    "                    flat_stat[k] = v\n",
    "            flat_stats.append(flat_stat)\n",
    "        return flat_stats\n",
    "    except Exception as e:\n",
    "        print(f\"[{fixture_id}] Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# === PARALLEL EXECUTION WITH PERIODIC SAVING ===\n",
    "all_stats = []\n",
    "completed = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "    futures = {executor.submit(fetch_fixture_stats, fid): fid for fid in remaining_ids}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching stats\"):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            all_stats.extend(result)\n",
    "        completed += 1\n",
    "\n",
    "        if completed % SAVE_EVERY == 0:\n",
    "            if all_stats:\n",
    "                df = pd.DataFrame(all_stats)\n",
    "                header = not os.path.exists(OUTPUT_FILE)\n",
    "                df.to_csv(OUTPUT_FILE, mode='a', header=header, index=False)\n",
    "                print(f\"🔄 Autosaved {len(all_stats)} rows after {completed} new fixtures.\")\n",
    "                all_stats = []\n",
    "\n",
    "# Final save\n",
    "if all_stats:\n",
    "    df = pd.DataFrame(all_stats)\n",
    "    header = not os.path.exists(OUTPUT_FILE)\n",
    "    df.to_csv(OUTPUT_FILE, mode='a', header=header, index=False)\n",
    "    print(f\"✅ Final save: {len(all_stats)} rows.\")\n",
    "\n",
    "print(f\"🎯 Done! Stats saved to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limit: None\n",
      "Remaining: None\n",
      "Reset: None\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://api.sportmonks.com/v3/football/fixtures/1\", params={\n",
    "    \"api_token\": API_TOKEN,\n",
    "    \"include\": \"statistics\"\n",
    "})\n",
    "\n",
    "# Show usage\n",
    "print(\"Limit:\", response.headers.get(\"X-RateLimit-Limit\"))\n",
    "print(\"Remaining:\", response.headers.get(\"X-RateLimit-Remaining\"))\n",
    "print(\"Reset:\", response.headers.get(\"X-RateLimit-Reset\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 76582 rows\n",
      "🔢 Columns: ['fixture_id', 'id', 'type_id', 'participant_id', 'data_value', 'location']\n",
      "\n",
      "📊 Stat type_id counts:\n",
      "type_id\n",
      "34      18902\n",
      "45      18640\n",
      "52      15056\n",
      "83       7834\n",
      "84      14048\n",
      "85        236\n",
      "1605     1866\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📌 Example stat rows:\n",
      "       fixture_id        id  type_id  participant_id  data_value location\n",
      "3             486  17278082       34              26         3.0     away\n",
      "4             486  17278095       45              16        55.0     home\n",
      "0             468  22501328       52              13         2.0     away\n",
      "436           849  14959145       83              14         0.0     home\n",
      "8             486  52391006       84              26         2.0     away\n",
      "16192        6518  18617910       85              22         0.0     home\n",
      "2             486  17278081     1605              16        54.0     home\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load stats file\n",
    "stats_df = pd.read_csv(\"/Users/sebastianvinther/Desktop/Sportsmonks/fixture_statistics_parallel.csv\")\n",
    "\n",
    "# Show basic info\n",
    "print(f\"✅ Loaded {len(stats_df)} rows\")\n",
    "print(\"🔢 Columns:\", stats_df.columns.tolist())\n",
    "\n",
    "# Count unique type_ids\n",
    "type_counts = stats_df['type_id'].value_counts().sort_index()\n",
    "\n",
    "# Show summary of type_id usage\n",
    "print(\"\\n📊 Stat type_id counts:\")\n",
    "print(type_counts)\n",
    "\n",
    "# Optional: show sample rows per type_id\n",
    "print(\"\\n📌 Example stat rows:\")\n",
    "print(stats_df.groupby('type_id').head(1).sort_values('type_id'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/dl4x3l3x1dd8twj43d1ddkx80000gn/T/ipykernel_36048/2729086848.py:15: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fixture_ids = pd.read_csv(FIXTURE_FILE)['id'].dropna().astype(int).tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from 146085 remaining fixtures (skipped 9456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   0%|          | 101/146085 [00:08<3:38:00, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 100 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   0%|          | 201/146085 [00:17<3:21:58, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 200 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   0%|          | 301/146085 [00:25<3:09:00, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 300 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   0%|          | 401/146085 [00:33<3:26:05, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 400 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   0%|          | 501/146085 [00:41<3:21:52, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 500 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   0%|          | 601/146085 [00:50<3:27:51, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 600 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   0%|          | 701/146085 [00:58<3:21:17, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 700 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 801/146085 [01:06<3:25:38, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 800 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 901/146085 [01:15<3:19:36, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 900 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 1001/146085 [01:23<3:22:51, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 1000 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 1101/146085 [01:32<3:27:04, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 1100 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 1201/146085 [01:41<3:24:59, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 1200 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 1301/146085 [01:49<3:21:12, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 1300 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 1401/146085 [01:58<3:32:11, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 1400 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 1501/146085 [02:07<3:39:13, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 1500 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 1601/146085 [02:16<3:50:12, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 1600 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 1701/146085 [02:24<3:27:13, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 1700 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|          | 1801/146085 [02:33<3:27:05, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 1800 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|▏         | 1901/146085 [02:42<3:26:36, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 1900 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|▏         | 2001/146085 [02:50<3:19:35, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 2000 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   1%|▏         | 2101/146085 [02:59<3:21:05, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 2100 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   2%|▏         | 2201/146085 [03:07<3:16:57, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 2200 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   2%|▏         | 2301/146085 [03:15<3:13:13, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 2300 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   2%|▏         | 2401/146085 [03:24<3:15:21, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 2400 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   2%|▏         | 2501/146085 [03:32<3:14:35, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 2500 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   2%|▏         | 2601/146085 [03:40<3:15:44, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 2600 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   2%|▏         | 2701/146085 [03:49<3:15:37, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Autosaved 0 rows after 2700 new fixtures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stats:   2%|▏         | 2793/146085 [03:56<3:22:20, 11.80it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 63\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(pending_ids), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching stats\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[1;32m     64\u001b[0m         result \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m waiter\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mwait(wait_timeout)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m     waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m all_stats \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m completed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mNUM_THREADS) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     61\u001b[0m     futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(fetch_fixture_stats, fid): fid \u001b[38;5;28;01mfor\u001b[39;00m fid \u001b[38;5;129;01min\u001b[39;00m pending_ids}\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(pending_ids), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching stats\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshutdown(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/thread.py:238\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 238\u001b[0m         t\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:1149\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:1169\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[1;32m   1170\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "API_TOKEN = \"oYeoAVFUTQpu7MfoFqbvyiYfgRRkuBWW0p2atkZnySe4X3xrHkjgGhOvI0pd\"\n",
    "FIXTURE_FILE = \"/Users/sebastianvinther/Desktop/Sportsmonks/fixtures_full.csv\"\n",
    "OUTPUT_FILE = \"/Users/sebastianvinther/Desktop/Sportsmonks/fixture_statistics_parallel.csv\"\n",
    "NUM_THREADS = 1\n",
    "SAVE_EVERY = 100\n",
    "\n",
    "# === LOAD FIXTURE IDS ===\n",
    "fixture_ids = pd.read_csv(FIXTURE_FILE)['id'].dropna().astype(int).tolist()\n",
    "\n",
    "# === RESUME LOGIC ===\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    done_df = pd.read_csv(OUTPUT_FILE, usecols=[\"fixture_id\"])\n",
    "    done_ids = set(done_df['fixture_id'].unique())\n",
    "else:\n",
    "    done_ids = set()\n",
    "\n",
    "pending_ids = [fid for fid in fixture_ids if fid not in done_ids]\n",
    "print(f\"Resuming from {len(pending_ids)} remaining fixtures (skipped {len(done_ids)})\")\n",
    "\n",
    "# === SHARED SESSION ===\n",
    "session = requests.Session()\n",
    "adapter = requests.adapters.HTTPAdapter(pool_connections=100, pool_maxsize=100)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "# === FUNCTION TO FETCH STATS ===\n",
    "def fetch_fixture_stats(fixture_id):\n",
    "    url = f\"https://api.sportmonks.com/v3/football/fixtures/{fixture_id}\"\n",
    "    params = {\"api_token\": API_TOKEN, \"include\": \"statistics\"}\n",
    "    try:\n",
    "        response = session.get(url, params=params, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return []\n",
    "        stats = response.json().get(\"data\", {}).get(\"statistics\", [])\n",
    "        flat_stats = []\n",
    "        for stat in stats:\n",
    "            flat_stat = {\"fixture_id\": fixture_id}\n",
    "            for k, v in stat.items():\n",
    "                if isinstance(v, dict):\n",
    "                    for sub_k, sub_v in v.items():\n",
    "                        flat_stat[f\"{k}_{sub_k}\"] = sub_v\n",
    "                else:\n",
    "                    flat_stat[k] = v\n",
    "            flat_stats.append(flat_stat)\n",
    "        return flat_stats\n",
    "    except Exception as e:\n",
    "        print(f\"[{fixture_id}] Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# === PARALLEL EXECUTION WITH RESUME + AUTOSAVE ===\n",
    "all_stats = []\n",
    "completed = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "    futures = {executor.submit(fetch_fixture_stats, fid): fid for fid in pending_ids}\n",
    "    with tqdm(total=len(pending_ids), desc=\"Fetching stats\") as pbar:\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                all_stats.extend(result)\n",
    "            completed += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            if completed % SAVE_EVERY == 0:\n",
    "                df = pd.DataFrame(all_stats)\n",
    "                df.to_csv(OUTPUT_FILE, mode='a', header=not os.path.exists(OUTPUT_FILE), index=False)\n",
    "                print(f\"🔄 Autosaved {len(all_stats)} rows after {completed} new fixtures.\")\n",
    "                all_stats = []\n",
    "\n",
    "# Final save\n",
    "if all_stats:\n",
    "    df = pd.DataFrame(all_stats)\n",
    "    df.to_csv(OUTPUT_FILE, mode='a', header=not os.path.exists(OUTPUT_FILE), index=False)\n",
    "    print(f\"✅ Final save: {len(all_stats)} remaining rows.\")\n",
    "\n",
    "print(f\"🎯 Done! All fixture stats saved to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "    futures = {executor.submit(fetch_fixture_stats, fid): fid for fid in fixture_ids}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching stats\"):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            all_stats.extend(result)\n",
    "\n",
    "# Save once all threads complete\n",
    "pd.DataFrame(all_stats).to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"✅ Done! Saved {len(all_stats)} rows to {OUTPUT_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
